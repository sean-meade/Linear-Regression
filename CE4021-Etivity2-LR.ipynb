{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook E-tivity 2 CE4021 Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student name: Peter O'Mahony"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student ID: 8361967"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Task Statement\n",
    "_The goal of this task is to create your own implementation of linear regression using your own functions to implement the required matrix manipulations._\n",
    "_Inspect the reference implementation and create functions for all the matrix manipulations required to implement the linear regression algorithm._\n",
    "\n",
    "_(Objective 1) Use these matrix manipulation functions in a new function that takes the data (X) and outputs (y) and returns the least squares estimate of the linear regression weight vector. Call this function 'fit'._\n",
    "\n",
    "_(Objective 2) Create a second function that uses the weights found by the fit method and a number of data points X to create new predictions. Call this function 'predict'._\n",
    "\n",
    "_(Objective 3) Finally, create a function that returns the weights found by the fit method. Call this function 'get_params'._\n",
    "\n",
    "_Please note:_\n",
    "\n",
    "_The function to calculate the inverse of a matrix need only be applicable to 2x2 matrices. All other functions should be able to handle matrices of arbitrary sizes._\n",
    "_Error handling is very useful to prevent matrices of incorrect sizes resulting in run-time errors._\n",
    "_Add appropriate comments (doc strings) to the functions you have created._\n",
    "_At this stage you should not create a class to encapsulate your code. Please add this element, if time permits, as part of your reflection._"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRAFT - FOR INITIAL REVIEW\n",
    "\n",
    "## Initial Thoughts\n",
    "This challenge is about creating functions that operate on matrices. Later those functions will need to become methods in a class.\n",
    "\n",
    "Somewhere in the resources implies that to estimate the least squares we use a formula like:\n",
    "$$ (X^T \\cdot X)^{-1} \\cdot X^T \\cdot y$$\n",
    "and I found that in Pep's Lessons video.  It's not clear to me how that formula is derived but I can precipiate from it that there are a few matrix manipulations/functions needed to use the formula:\n",
    "1. Transpose\n",
    "2. Dot Product\n",
    "3. Inverse\n",
    "\n",
    "and it appears that that is the scope of Part 1 of this E-tivity.  I'm fascinated that there is no sign of a square root or Pythagorus in this and yet we are going to evaluate distances from a line.  A shake of magic no doubt.\n",
    "\n",
    "## Approach\n",
    "I am going to write the functions noted above and then define a collection of tests that uses both them and the numpy versions and compares the results.\n",
    "\n",
    "The Dot product looks like the most complex so I will start with that.  I wrote out a pair of generic matrices on paper to help me consider the coordinates of each element in a matrix and determine how it will be used:\n",
    "\n",
    "$$\n",
    "\\left [\n",
    "\\begin{matrix}\n",
    "A_{11} & A_{12} \\\\\n",
    "A_{21} & A_{22}\n",
    "\\end{matrix}\n",
    "\\right ]\n",
    ".\n",
    "\\left [\n",
    "\\begin{matrix}\n",
    "B_{11} & B_{12} & B_{13} \\\\\n",
    "B_{21} & B_{22} & B_{23} \n",
    "\\end{matrix}\n",
    "\\right ]\n",
    "=\n",
    "\\left [\n",
    "\\begin{matrix}\n",
    "C_{11} & C_{12} & C_{13} \\\\\n",
    "C_{21} & C_{22} & C_{23} \n",
    "\\end{matrix}\n",
    "\\right ]\n",
    "$$\n",
    "\n",
    "where, for example, \n",
    "$ C_{11} = A_{11}B_{11}+A_{12}B_{21} $ and $ C_{12} = A_{11}B_{12}+A_{12}B_{22} $ etc\n",
    "\n",
    "Some validation will be necessary.  For Dot Product of A.B, the number of columns of A must match the number of rows of B. The resulting matrix will have dimensions of the number of rows of A times the number of columns of B.\n",
    "\n",
    "The arrangement of for loops to effect this function is daunting so I thought about ways to help myself track the output.  When considering $ C_{11} $ in this example, I noticed the pattern where the value is the sum of n terms and that n is equal to the number of columns in A (or rows in B). This suggested to me that I could take an iterative approach to calculating the value of each element in the resulting matrix and that I could use a for loop to determine the value of each term and add it to whatever the value of that element was.\n",
    "\n",
    "I knew it would take me more time to work out sample calculations for a number of test matrices while developing the code so I came up with an idea to skip the calculations but still prove the result. I used strings and concatenation to produce the output in a similar way to that shown above and included the positions/coordinates of each element in the result.\n",
    "\n",
    "## Calculating the Inverse of a matrix\n",
    "I found this formula here https://www.mathsisfun.com/algebra/matrix-inverse.html:\n",
    "$$\n",
    "\\left [\n",
    "\\begin{matrix}\n",
    "a & b \\\\\n",
    "c & d\n",
    "\\end{matrix}\n",
    "\\right ]\n",
    "^{-1}\n",
    "=\n",
    "\\frac {1}{ad-bc}\n",
    "\\left [\n",
    "\\begin{matrix}\n",
    "d & -b \\\\\n",
    "-c & a\n",
    "\\end{matrix}\n",
    "\\right ]\n",
    "$$\n",
    "\n",
    "and it says that $ {ad-bc} $ is the determinant of the matrix and that seems important so I'm going to give it its own function because it'll probably be handy in the future.\n",
    "\n",
    "Also, it becomes clear at this point that I will need to multiply a matrix by a scalar so I will need a function for that.\n",
    "\n",
    "## Testing\n",
    "I will compare each of my functions with the numpy versions over a range of matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Calculation\n",
    "\n",
    "In addition to automated testing, I manually calculated some sample data as follows:\n",
    "I'll invent a very simple scenario of book sales to customers that are in a loyalty scheme.  We want to be able to predict how much a customer will spend during a promotion based on their past behaviour.  Our historical data are:\n",
    "\n",
    "|points|spent|\n",
    "|------|------|\n",
    "|874     |14.50     |\n",
    "|982     |15.25     |\n",
    "|1100    | 17.00    |\n",
    "| 1298   | 16.75 |\n",
    "\n",
    "\n",
    "Let's create the matrices X and y so that we can apply our formula $$ (X^T \\cdot X)^{-1} \\cdot X^T \\cdot y$$\n",
    "\n",
    "$$\n",
    "X = \n",
    "\\left [\n",
    "\\begin{matrix}\n",
    "1 & 874 \\\\\n",
    "1 & 982 \\\\\n",
    "1 & 1100 \\\\\n",
    "1 & 1298\n",
    "\\end{matrix}\n",
    "\\right ]\n",
    "y =\n",
    "\\left [\n",
    "\\begin{matrix}\n",
    "14.50 \\\\ \n",
    "15.25  \\\\\n",
    " 17.00    \\\\\n",
    " 16.75  \n",
    "\\end{matrix}\n",
    "\\right ]\n",
    "$$\n",
    "\n",
    "$$\n",
    "X^T = \n",
    "\\left [\n",
    "\\begin{matrix}\n",
    "1 & 1 & 1 & 1 \\\\\n",
    "874 & 982 & 1100 & 1298\n",
    "\\end{matrix}\n",
    "\\right ]\n",
    "$$\n",
    "\n",
    "$$\n",
    "X^T.X = \n",
    "\\left [\n",
    "\\begin{matrix}\n",
    "1 & 1 & 1 & 1 \\\\\n",
    "874 & 982 & 1100 & 1298\n",
    "\\end{matrix}\n",
    "\\right ]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3035729104.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    <hr style=\"border:2px solid gray\"> </hr>\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "<hr style=\"border:2px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg_weights(X,y):\n",
    "    # Calculation of weights using pseudo-inverse. Note that X needs to contain the bias of 1\n",
    "    return np.linalg.inv((X.T.dot(X))).dot(X.T).dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg_predict(w,X):\n",
    "    # Calculation of outputs given weights and data (X). Note that X needs to contain the bias of 1. \n",
    "    out=[]\n",
    "    for x in X:\n",
    "        out.append(w.T.dot(x))\n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim(matrix: list) -> list:\n",
    "    \"\"\"\n",
    "    This returns a list of dimensions of the matrix.\n",
    "    It is the first recursive function I have used in python and am including it for future reference.\n",
    "    It comes from https://stackoverflow.com/questions/17531796/find-the-dimensions-of-a-multidimensional-python-array\n",
    "    \"\"\"\n",
    "    if not type(matrix) == list:\n",
    "        #print(f'dim: type is {type(matrix)}')\n",
    "        return []\n",
    "    return [len(matrix)] + dim(matrix[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error checking functions\n",
    "These functions raise an exception and halt execution unless the specified requirement is met.  I took this approach to increase the legibility of the individual matrix operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def require_to_be_square(matrix: list[list[float]]) -> None:\n",
    "    \"\"\"\n",
    "    Raises an error if the matrix is not square\n",
    "    \"\"\"\n",
    "    if (len(matrix) != len(matrix[0])):\n",
    "        raise ValueError(f\"This matrix must be square to get its inverse but the dimensions are {dim(matrix)}\")\n",
    "\n",
    "def require_to_be_2x2(matrix: list[list[float]]) -> None:\n",
    "    \"\"\"\n",
    "    Raises an error if the matrix is not 2x2\n",
    "    \"\"\"\n",
    "    if (len(matrix) != 2):\n",
    "        raise ValueError(f\"This matrix must have 2x2 dimensions\")\n",
    "\n",
    "def require_at_least_two_dimensions(matrix: list[list[float]]) -> None:\n",
    "    \"\"\"\n",
    "    Raises an error if the matrix has fewer than two dimensions\n",
    "    \"\"\"\n",
    "    # get the dimensions of the matrix\n",
    "    dim_matrix = dim(matrix)\n",
    "\n",
    "    if (len(dim_matrix) < 2): # Verify that we have at least two dimensions\n",
    "        raise ValueError(f\"The matrix must have at least two dimensions but it has {len(dim_matrix)} dimensions\")\n",
    "\n",
    "def require_colsA_equal_rowsB(A: list[list[float]], B: list[list[float]]) -> None:\n",
    "    \"\"\"\n",
    "    Raises an error if the number of columns in A does not match the number of rows in B\n",
    "    \"\"\"\n",
    "    if (len(A[0]) != len(B)):\n",
    "        raise ValueError(f\"The number of columns in A ({len(A[0])}) must match the number of rows in B ({len(B)})\"\n",
    "                         f\"\\nA={A}, B={B}\")\n",
    "\n",
    "def require_same_dimensions(A: list[list[float]], B: list[list[float]]) -> None:\n",
    "    \"\"\"\n",
    "    Raises an error if the dimensions of A do not match those of B\n",
    "    \"\"\"\n",
    "    dim_A, dim_B = dim(A), dim(B)\n",
    "    if (dim_A != dim_B):\n",
    "        raise ValueError(f'The matrices must have the same dimensions (A has {dim_A} and B has {dim_B})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_matrix(matrix: list[list[float]]) -> list[list[float]]:\n",
    "    \"\"\"\n",
    "    This transposes the matrix by switching the rows and columns and returns a new matrix\n",
    "    \"\"\"\n",
    "    # It uses the python List Comprehension feature to navigate to each element in the matrix\n",
    "    return [[matrix[row][col] for row in range(0,len(matrix))] for col in range(0,len(matrix[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_matrix(matrix: list[list[float]], scalar: float) -> list:\n",
    "    \"\"\"\n",
    "    This multiplies each element in the matrix by a scalar and returns a new matrix\n",
    "    \"\"\"\n",
    "    # It uses the python List Comprehension feature to navigate to each element in the matrix and it \n",
    "    # multiplies that element by the scalar\n",
    "    return [[matrix[row][col]*scalar for col in range(0,len(matrix[0]))] for row in range(0,len(matrix))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(A: list[list[float]], B: list[list[float]], show_vars: bool = False) -> list[list[float]]:\n",
    "    \"\"\"\n",
    "    This determines the dot product of two matrices, A and B and returns a new matrix.\n",
    "    The show_vars parameter, if true, will print a representation of the value of each element in the new\n",
    "    matrix\n",
    "    \"\"\"\n",
    "    # check that all conditions for the dot product have been met by the two matrices\n",
    "    require_at_least_two_dimensions(A)\n",
    "    require_at_least_two_dimensions(B)\n",
    "    require_colsA_equal_rowsB(A,B)\n",
    "    \n",
    "    # create new matrices with the same dimensions required by the dot product result\n",
    "    C = [[''  for row in range(0,len(B[0]))] for col in range(0,len(A))] # initialise string array for debug output\n",
    "    D = [[0.0 for row in range(0,len(B[0]))] for col in range(0,len(A))] # initialise float array for the new matrix\n",
    "   \n",
    "    for row in range(0,len(A)):             # rows from A\n",
    "        for col in range(0,len(B[0])):      # cols from B\n",
    "            for term in range(0,len(B)):    # terms = number of columns in A (or rows in B)\n",
    "                C[row][col] += f\" + A{row+1}{term+1}.B{term+1}{col+1}\"\n",
    "                D[row][col] += float(A[row][term] * B[term][col])        # add each term to the previous so that we sum\n",
    "                \n",
    "    if show_vars:\n",
    "        print('Dot Product showing terms:\\n', C) # show the string result\n",
    "        \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_determinant(matrix: list[list[float]]) -> float:\n",
    "    \"\"\"\n",
    "    This calculates the determinant of a square 2x2 matrix as ad-bc where\n",
    "    the matrix is [[a,b],[c,d]]\n",
    "    \"\"\"\n",
    "    # check that all conditions required to calculate the determinant have been met by the matrix\n",
    "    require_to_be_square(matrix)\n",
    "    require_to_be_2x2(matrix)\n",
    "    \n",
    "        # a b\n",
    "        # c d  => determinant is ad - bc\n",
    "    return float(matrix[0][0] * matrix[1][1]) - (matrix[0][1] * matrix[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the debug output\n",
    "dot_product([[3,1],[6,9]],[[4,-7],[1,-4]],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse(matrix: list[list[float]]) -> list[list[float]]:\n",
    "    \"\"\"\n",
    "    This returns the inverse of a square matrix\n",
    "    \"\"\"\n",
    "    # check that all conditions required to calculate the inverse have been met by the matrix\n",
    "    require_to_be_square(matrix)\n",
    "    \n",
    "    determinant = calc_determinant(matrix)\n",
    "\n",
    "    if (not determinant):\n",
    "        raise ValueError(f\"We cannot inverse a matrix with a zero determinant\")\n",
    "        \n",
    "    inv_determinant: float = 1/determinant \n",
    "    \n",
    "    # map the matrix like this:\n",
    "    # a b =>  d -b\n",
    "    # c d    -c  a\n",
    "    return multiply_matrix( [ [ matrix[1][1], -matrix[0][1] ], [ -matrix[1][0], matrix[0][0] ] ], inv_determinant )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_compare(np_array: np.array, a_list: list[list[float]]) -> bool:\n",
    "    '''\n",
    "    Compares the first parameter, a numpy array, with the second, an equivalent list.  \n",
    "    It uses the NumPy allclose function to allow a degree of tolerance for mismatches caused \n",
    "    by floating point or rounding issues.\n",
    "    '''\n",
    "    # This was the version before I discovered np.allclose(). precision was an integer parameter to this function\n",
    "    # return np.array_equal(np_array.round(precision), np.array(a_list).round(precision))\n",
    "    return np.allclose(np_array, np.array(a_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the home grown functions and compare with NumPy equivalents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are our test data with some random content\n",
    "test_matrices = (\n",
    "    [[1,2],[3,4]],\n",
    "    [[9, 10], [10, 16]],\n",
    "    np.random.randint( 25, size=(2, 2)).tolist(), # get numpy to generate a 2x2 matrix of random numbers\n",
    "    np.random.randint(-999,999, size=(3, 3)).tolist(), # a 3x3 matrix of +ve and -ve random numbers\n",
    "    [[1,2,3,4,5],[6,-1,8,9,10]],\n",
    "    [[3.3,2.2,1.1],[4,4,4],[7,-7.7,-7]],\n",
    "    )\n",
    "\n",
    "# a sample 2x2 matrix to test our dot product\n",
    "test_square_matrix = [[9,8],[7,6]]\n",
    "\n",
    "compare_msg: str = 'Result matches? '\n",
    "for index, test_matrix in enumerate(test_matrices):\n",
    "    print('-'*40)\n",
    "    print(f'Test #{index}:\\n',test_matrix)\n",
    "    \n",
    "    # Test Transposition\n",
    "    my_transpose_res = transpose_matrix(test_matrix)\n",
    "    print('Transposed\\n',\n",
    "          my_transpose_res,\n",
    "          compare_msg,\n",
    "          np_compare(np.array(test_matrix).T,\n",
    "                     my_transpose_res))\n",
    "    \n",
    "    # Test Multiplication\n",
    "    scalar = 10\n",
    "    my_multiply_res = multiply_matrix(test_matrix, scalar)\n",
    "    print(f'Multiplied by {scalar}\\n',\n",
    "          my_multiply_res,\n",
    "          compare_msg,\n",
    "          np_compare(np.array(test_matrix)*scalar,\n",
    "                     my_multiply_res))\n",
    "    \n",
    "    # Tests on square matrices\n",
    "    if (len(test_matrix[0]) == len(test_square_matrix)):\n",
    "        # Test Dot Product\n",
    "        my_dot_res = dot_product(test_matrix, test_square_matrix)\n",
    "        print(f'Dotted with {test_square_matrix}\\n',\n",
    "              my_dot_res,\n",
    "              compare_msg,\n",
    "              np_compare(np.array(test_matrix).dot(test_square_matrix),\n",
    "                         my_dot_res))\n",
    "\n",
    "        # Test Inverse\n",
    "        my_inv_res = inverse(test_matrix)\n",
    "        print(f'Inversed\\n',\n",
    "              my_inv_res,\n",
    "              compare_msg,\n",
    "              np_compare(np.linalg.inv(np.array(test_matrix)), \n",
    "                         my_inv_res))\n",
    "        my_res_res = dot_product(test_matrix, my_inv_res) # should return the identity matrix\n",
    "        print(f'Reversed to Identity\\n',\n",
    "              my_res_res,\n",
    "              compare_msg,\n",
    "              np_compare(np.linalg.inv(np.array(my_res_res)), \n",
    "                         my_res_res))\n",
    "    else:\n",
    "        print('Skipping Dot Product and Inverse for non-square matrix')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from file (including bias of 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('lr_data.csv', delimiter=',')\n",
    "X = data[:,0:2]\n",
    "y= [[data[i,2]] for i in range(0,len(data[:,2]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply data to linear regression algorithm to obtain weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = linreg_weights(X,y)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra matrix operations\n",
    "I could not see where the requirement for these functions were in the Task specification but Adam said we should include them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(A, B):\n",
    "    \"\"\"\n",
    "    Perform elementwise addition on two equally dimensioned matrices\n",
    "    \"\"\"\n",
    "    require_same_dimensions(A,B)\n",
    "    return [ [A[i][j]+B[i][j] for j in range(0,len(A[0])) ] for i in range(0,len(A)) ]\n",
    "\n",
    "def subtract(A, B):\n",
    "    \"\"\"\n",
    "    Perform elementwise subtraction on two equally dimensioned matrices\n",
    "    \"\"\"\n",
    "    require_same_dimensions(A,B)\n",
    "    return [ [A[i][j]-B[i][j] for j in range(0,len(A[0])) ] for i in range(0,len(A)) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data for matrix operations\n",
    "test_A = [[1,1,1],[1,-1,1]]\n",
    "test_B = [[1,1,1],[1,1,1]]\n",
    "\n",
    "# Test the add matrix operation\n",
    "add_res = add(test_A,test_B)\n",
    "np_add_res = np.array(test_A)+np.array(test_B)\n",
    "np_compare(np.array(test_A)+np.array(test_B), add_res)\n",
    "print('our result\\n',add_res,'\\nnp result\\n',np_add_res,'\\nEqual? ',np_compare(np_add_res, add_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the subtract matrix operation\n",
    "sub_res = subtract(test_A,test_B)\n",
    "np_sub_res = np.array(test_A)-np.array(test_B)\n",
    "print('our result\\n',sub_res,'\\nnp result\\n',np_sub_res,'\\nEqual? ',np_compare(np_sub_res, sub_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Level Functions/Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X: list[list[float]], y: list[list[float]]) -> list[list[float]]:\n",
    "    \"\"\"\n",
    "    Calculate the weights (slope and offset) using pseudo-inverse. \n",
    "    Note that X needs to contain the bias of 1.\n",
    "    \"\"\"\n",
    "    \"\"\" (this second docscript is not displayed with help)\n",
    "    This is the first objective of the task (see The Task Statement above).\n",
    "    For reference, the supplied function for linreg_weights is:\n",
    "        np.linalg.inv(\n",
    "            (X.T\n",
    "            .dot(X))\n",
    "            )\n",
    "            .dot(X.T)\n",
    "            .dot(y)\n",
    "    \"\"\"\n",
    "    # break into more manageable units for clarity (at a cost of memory)\n",
    "    XT        = transpose_matrix(X)\n",
    "    XTdotX    = dot_product( XT, X)\n",
    "    invXTdotX = inverse( XTdotX )\n",
    "    step4     = dot_product( invXTdotX,  transpose_matrix(X))\n",
    "    final     = dot_product( step4, y)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(X: list[list[float]], y: list[list[float]]) -> list[list[float]]:\n",
    "    \"\"\"\n",
    "    The requirement for this function is not clear.  The task states that we should \"create a function\n",
    "    that returns the weights found by the fit method\". I am guessing that it is required for compatibility\n",
    "    with other NumPy ML classes that have methods with the same names (fit, predict and get_params).\n",
    "    My implementation just calls the fit function passing through the parameters.\n",
    "    \"\"\"\n",
    "    return fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test the fit function with the same data that we used for the NumPy implementation.  To do this we need to convert the X data that were read from the CSV file into an NumPy array structure into a native list structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call our native fit function with the X data converted to a list\n",
    "my_weights = fit(X.tolist(), y)\n",
    "my_weights_by_GP = get_params(X.tolist(), y)\n",
    "print('get_params compares OK? ',np_compare(weights, my_weights_by_GP))\n",
    "print('np weights\\n', weights)\n",
    "print('my weights\\n', my_weights)\n",
    "print('fit compares OK? ',np_compare(weights, my_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(weights: list[list[float]], X) -> list:\n",
    "    \"\"\"\n",
    "    This function applies the weights determined by the fit function to a selection of data points in the\n",
    "    sample and returns a list of predicted y values that sit on the line represented by the weights\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    This is required in the Task Statement above.  \"Create a second function that uses the weights found \n",
    "    by the fit method and a number of data points X to create new predictions. Call this function 'predict'.\"\"\n",
    "    \"\"\"\n",
    "    predictions=[]\n",
    "    weightsT = transpose_matrix(weights)  # transpose the weights outside the loop for efficiency\n",
    "    for x in X:\n",
    "        z = dot_product(weightsT, transpose_matrix([x]))\n",
    "        predictions.append(z[0])\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_values(matrix, column_number):\n",
    "    \"\"\"\n",
    "    This returns a list of values from column column_number in the matrix.\n",
    "    \"\"\"\n",
    "    return [row[column_number] for row in matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of test values representing x values that should be fitted to our least squares line\n",
    "test_vals = [[1,0.5],[1,1.25],[1,1.7],[1,2.9],[1,3.5]]\n",
    "\n",
    "# get the predictions for our y values\n",
    "predicted_y = predict(weights,test_vals)\n",
    "\n",
    "# extract the x values from the test values because we don't need the 1 values from column 0\n",
    "test_vals_x = column_values(test_vals,1)\n",
    "\n",
    "# determine the maximum value for the x axis by adding a bit to the maximum x values from our two datasets\n",
    "x_axis_len = max(max(X[:,1]),max(test_vals_x))+0.5\n",
    "\n",
    "# same for y but using max on predicted_y returns what we want in the first element of a single element list\n",
    "y_axis_len = max(max(predicted_y),max(X[:,1]))\n",
    "y_axis_len = y_axis_len[0] + 50\n",
    "\n",
    "# calculate an appropriate range for the x axis\n",
    "ind = np.arange(0, x_axis_len, 0.1)\n",
    "\n",
    "# plot our line represented by the weights (least squares line)\n",
    "plt.plot(ind, ind*weights[1]+weights[0],'r',label='LSQ')\n",
    "\n",
    "# plot the data from our CSV for comparison\n",
    "plt.plot(X[:,1], y, '.', color='green',label='Actual data from CSV')\n",
    "\n",
    "# plot our predicted values from our test_vals list. These should fall onto our least squares line\n",
    "plt.plot(test_vals_x, predicted_y, 'o', markersize=10, color='purple',label='Predictions')\n",
    "\n",
    "plt.legend()  # Add a legend which will show the labels\n",
    "\n",
    "# set the limits of our axes so that our data are all visible regardless of our sample distribution\n",
    "# now I understand why Pep used the _ = in his presentation. It stops the plt.axis function from \n",
    "# showing the values of the axes.\n",
    "_ = plt.axis([0, x_axis_len, -100, y_axis_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeastSquares:\n",
    "    \"\"\"\n",
    "    The LeastSquares class can be expanded by moving the code from the functions above\n",
    "    into the public methods below. It's not clear to me how much of this we need to do for this\n",
    "    task so, due to time constraints, I'm just putting in the skeleton to demonstrate the syntactic\n",
    "    structure of the class.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X: list[list[float]], y: list[list[float]]) -> list[list[float]]:\n",
    "        return fit(X, y)\n",
    "    \n",
    "    def predict(self, weights: list[list[float]], X) -> list:\n",
    "        return predict(weights, X)\n",
    "    \n",
    "    def get_params(self, X: list[list[float]], y: list[list[float]]) -> list[list[float]]:\n",
    "        return get_params(X, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[1,874],[1,982],[1,1100],[1,1298]]\n",
    "print(transpose(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was delightfully challenging but time consuming and it required more effort than I had planned.  I got some feedback on my draft and it influenced my thinking where it was relevant to my approach.\n",
    "\n",
    "Like etivity 1, this task was about using native python code to do the heavy lifting but two libraries were available and I chose to use them to validate my work by using test cases that apply the same data to my native versions and the NumPy versions and compare the result.  While this took a bit of research into the library I am confident that it will pay dividends as we will make much use of it.  This approach also gave me confidence that my code was an accurate reflection of what was required, at least in terms of the operational functions.\n",
    "\n",
    "I hardly considered anything other than lists of lists to represent matrices and I learnt a lot about how to specify subsets of those structures where appropriate.  There was plenty of documentation available on the meaning of the main operations (e.g. dot product, inverse) and I found it straightforward to figure out how to implement them in python.  The clues in the Notebook template guided me in determining how to glue together the functions I had developed but I can't say I could derive the Least Squares formula algebraically now.\n",
    "\n",
    "Looking at the other submissions I don't see examples of how people are going to demonstrate how to reap the benefits of this work.  I have included some new test sample data points and graphed them over the data we were given. This illustrates to me how useful the algorithm will be for prediction.  An example I gave in feedback to a peer was in a scenario where we had data representing the age and weight of an individual.  We can use linear regression to determine the slope and position required to draw a line on a graph that predicts the weight for an unknown individual based on their age.  This work also encouraged me to explore the matplotlib library and I found it easy to customise the markers and axes to suit the application.\n",
    "\n",
    "I created a structure for a LeastSquares class as requested for inclusion in the reflection.\n",
    "\n",
    "Pierce showed me a one liner to transpose a matrix that appeared very efficient but not immediately understandable so I did not use it. Jason reminded me to use more meaningful names for functions and variables.  No peer material was used in my code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
